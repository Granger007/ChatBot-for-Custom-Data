# ğŸ“„ Chatbot for Your Data

A simple, functional chatbot that allows users to interact with their own PDF documents using natural language. Built using **Flask**, **Langchain**, and **Retrieval-Augmented Generation (RAG)**, the chatbot extracts relevant information from the document and uses an LLM (like OpenAI's GPT) to answer user queries.

---

## ğŸš€ Features

* ğŸ§  Chat with any PDF file using LLMs (Large Language Models)
* ğŸ” Retrieval-Augmented Generation (RAG) to provide accurate, context-aware answers
* ğŸŒ Web interface built with Flask
* ğŸ“š Uses Langchain to manage document ingestion, chunking, embedding, and retrieval

---

## ğŸ’  Tech Stack

* **Python**
* **Flask** â€“ Web server and frontend interface
* **Langchain** â€“ LLM framework for RAG pipelines
* **OpenAI API** â€“ For language generation
* **FAISS / Chroma** â€“ For vector-based document retrieval
* **PyMuPDF / pdfplumber** â€“ For PDF parsing

---

## ğŸ“‚ Project Structure

```
chatbot-for-your-data/
â”œâ”€â”€ app.py                  # Flask backend
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html          # Frontend UI
â”œâ”€â”€ static/
â”‚   â””â”€â”€ styles.css          # Basic styling
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ rag_pipeline.py     # PDF loading, chunking, embedding, and querying
â”œâ”€â”€ uploads/
â”‚   â””â”€â”€ (user PDFs)         # Uploaded PDF files
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Brief Idea about the project
```

---

## âš™ï¸ Setup Instructions

1. **Clone the repo**

   ```bash
   git clone https://github.com/your-username/chatbot-for-your-data.git
   cd chatbot-for-your-data
   ```

2. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

3. **Set up your OpenAI API key**

   ```bash
   export OPENAI_API_KEY=your_openai_key_here
   ```

4. **Run the app**

   ```bash
   python app.py
   ```

5. **Open your browser** Go to `http://localhost:5000` to interact with the chatbot.

---

## ğŸ§ª How It Works

* Upload a PDF file via the web interface.
* The system reads and splits the document into chunks.
* Embeddings are created and stored in a vector database.
* When a user types a question, relevant chunks are retrieved and passed to the LLM.
* The LLM generates a context-based answer using both the question and retrieved document chunks.

---

## ğŸ“Œ To Do / Improvements

* Add multi-PDF support
* File caching for faster reloading
* Add file type support (e.g., DOCX)
* Integrate speech input and TTS output (future extension)
---

## ğŸ™Œ Acknowledgements

* [Langchain](https://www.langchain.com/)
* [OpenAI](https://openai.com/)
* [FAISS](https://github.com/facebookresearch/faiss)
